# SKY-STT - é«˜æ€§èƒ½è¯­éŸ³è½¬æ–‡å­—å·¥å…·é›†


ä¸€ä¸ªå¼ºå¤§çš„å¤šå¼•æ“è¯­éŸ³è½¬æ–‡å­—(STT)å·¥å…·é›†ï¼Œæ”¯æŒæœ¬åœ°å¤„ç†å’Œäº‘ç«¯APIï¼Œæä¾›é«˜ç²¾åº¦çš„è¯­éŸ³è¯†åˆ«ã€è¯´è¯äººåˆ†å‰²å’Œå¤šæ ¼å¼è¾“å‡ºåŠŸèƒ½ã€‚

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

### ğŸš€ åŒå¼•æ“æ”¯æŒ
- **æœ¬åœ°å¼•æ“**: åŸºäº FasterWhisper + Pyannoteï¼Œå®Œå…¨ç¦»çº¿è¿è¡Œ
- **äº‘ç«¯å¼•æ“**: åŸºäº Google Gemini APIï¼Œæ”¯æŒéŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«**: æ”¯æŒå¤šç§è¯­è¨€ï¼Œä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡é«˜
- **è¯´è¯äººåˆ†å‰²**: è‡ªåŠ¨è¯†åˆ«å’Œæ ‡è®°å¤šä¸ªè¯´è¯äºº
- **å¤šæ ¼å¼æ”¯æŒ**: è¾“å…¥æ”¯æŒ wavã€mp3ã€m4aã€flacã€oggã€opus ç­‰æ ¼å¼
- **å¤šè¾“å‡ºæ ¼å¼**: txtã€srtã€json ç­‰å¤šç§è¾“å‡ºæ ¼å¼
- **æ‰¹å¤„ç†æ¨¡å¼**: æ”¯æŒç›®å½•æ‰¹é‡å¤„ç†
- **GPU åŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹å’Œä½¿ç”¨ CUDA GPU
- **å®æ—¶è¿›åº¦**: è¯¦ç»†çš„å¤„ç†è¿›åº¦å’Œæ—¥å¿—è¾“å‡º

### ğŸ› ï¸ ä¾¿åˆ©å·¥å…·
- **æ¨¡å‹è½¬æ¢å™¨**: è‡ªåŠ¨ä¸‹è½½å’Œè½¬æ¢ Whisper æ¨¡å‹
- **æ¨¡å‹ç®¡ç†å™¨**: ä¸€é”®ä¸‹è½½é…ç½® Pyannote è¯´è¯äººåˆ†å‰²æ¨¡å‹
- **æ ¼å¼è½¬æ¢**: å†…ç½®éŸ³é¢‘æ ¼å¼è‡ªåŠ¨è½¬æ¢

## ğŸ“‹ ç›®å½•

- [å®‰è£…æŒ‡å—](#-å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨è¯´æ˜](#-è¯¦ç»†ä½¿ç”¨è¯´æ˜)
- [å·¥å…·ä»‹ç»](#-å·¥å…·ä»‹ç»)
- [æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [å¼€å‘è¯´æ˜](#-å¼€å‘è¯´æ˜)
- [è®¸å¯è¯](#-è®¸å¯è¯)

## ğŸš€ å®‰è£…æŒ‡å—

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)
- FFmpeg (ç”¨äºéŸ³é¢‘æ ¼å¼è½¬æ¢)

### å¿«é€Ÿå®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/SKY-STT.git
cd SKY-STT

# å®‰è£…ä¾èµ– - åŸºç¡€ç‰ˆæœ¬
pip install faster-whisper soundfile numpy

# å®‰è£…ä¾èµ– - å®Œæ•´ç‰ˆæœ¬ (åŒ…å«è¯´è¯äººåˆ†å‰²)
pip install faster-whisper pyannote.audio==3.1.1 soundfile numpy pyyaml torch torchaudio

# Gemini API æ”¯æŒéœ€è¦é¢å¤–ä¾èµ–
pip install requests urllib3

# æ¨¡å‹ä¸‹è½½å’Œè½¬æ¢å·¥å…·ä¾èµ–
pip install huggingface_hub ctranslate2 tqdm

# å®‰è£… FFmpeg (æ¨è)
# Ubuntu/Debian:
sudo apt install ffmpeg
# macOS:
brew install ffmpeg
# Windows: ä¸‹è½½å¹¶æ·»åŠ åˆ° PATH
```

### GPU æ”¯æŒ (å¯é€‰ä½†æ¨è)

å¦‚æœæœ‰ NVIDIA GPUï¼Œå®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorchï¼š

```bash
# CUDA 11.8
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Hugging Face Token é…ç½® (è¯´è¯äººåˆ†å‰²å¿…éœ€)

è¯´è¯äººåˆ†å‰²åŠŸèƒ½éœ€è¦ä» Hugging Face ä¸‹è½½æ¨¡å‹ï¼ŒæŸäº›æ¨¡å‹éœ€è¦è®¿é—®æƒé™ï¼š

1. **æ³¨å†Œ Hugging Face è´¦å·**: [https://huggingface.co](https://huggingface.co)
2. **ç”³è¯·æ¨¡å‹è®¿é—®æƒé™**: è®¿é—® [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1) å¹¶æ¥å—è®¸å¯æ¡æ¬¾
3. **ç”Ÿæˆ Token**: åœ¨ [è®¾ç½®é¡µé¢](https://huggingface.co/settings/tokens) åˆ›å»ºè®¿é—® Token
4. **é…ç½®ç¯å¢ƒå˜é‡**:
```bash
export HF_TOKEN=your_huggingface_token_here
# æˆ–åœ¨ ~/.bashrc ä¸­æ·»åŠ ä¸Šè¿°è¡Œ
```

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ¨¡å‹

#### ä¸‹è½½ Whisper æ¨¡å‹
```bash
# ä½¿ç”¨å†…ç½®å·¥å…·ä¸‹è½½å¹¶è½¬æ¢ Whisper æ¨¡å‹
python tools/convert_whisper.py --model_id openai/whisper-large-v3 --output_dir ./models/whisper-large-v3

# æˆ–è€…ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
python tools/convert_whisper.py --model_id Belle-2/Belle-whisper-large-v3-zh --output_dir ./models/whisper-zh
```

#### ä¸‹è½½è¯´è¯äººåˆ†å‰²æ¨¡å‹ (å¯é€‰)
```bash
# ä¸‹è½½ Pyannote è¯´è¯äººåˆ†å‰²æ¨¡å‹ (éœ€è¦ Hugging Face Token)
python tools/get_Pyannote_model.py --output ./pyannote-models

# æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½® Token
export HF_TOKEN=your_huggingface_token
python tools/get_Pyannote_model.py --output ./pyannote-models --token $HF_TOKEN
```

### 2. åŸºç¡€è½¬å½•

```bash
# åŸºç¡€è¯­éŸ³è½¬æ–‡å­—
python stt.py --audio audio.wav --model ./models/whisper-large-v3 --output result.txt

# æŒ‡å®šè¯­è¨€å’Œè®¾å¤‡
python stt.py -a audio.mp3 -m ./models/whisper-zh -o result.txt -l zh -d cuda

# ç”Ÿæˆ SRT å­—å¹•
python stt.py -a video.m4a -m ./models/whisper-large-v3 -o subtitles.srt -f srt
```

### 3. è¯´è¯äººåˆ†å‰²

```bash
# å¯ç”¨è¯´è¯äººåˆ†å‰²
python stt.py -a meeting.wav -m ./models/whisper-large-v3 -o meeting.txt \
  --speakers --speaker-model ./pyannote-models/speaker-diarization-3.1

# æŒ‡å®šè¯´è¯äººæ•°é‡å’ŒèŒƒå›´
python stt.py -a discussion.mp3 -m ./models/whisper-large-v3 -o discussion.srt \
  --speakers --speaker-model ./pyannote-models/speaker-diarization-3.1 \
  --num-speakers 3 --min-speakers 2 --max-speakers 5 -f srt
```

### 4. æ‰¹é‡å¤„ç†

```bash
# æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
python stt.py --batch -a ./audio_folder/ -m ./models/whisper-large-v3 \
  --output-dir ./results/ -f json
```

### 5. ä½¿ç”¨ Gemini API

```bash
# ä½¿ç”¨ Gemini API å¤„ç†éŸ³é¢‘
python gemini-stt.py --input audio.mp3 --output subtitles.srt \
  --api-key YOUR_GEMINI_API_KEY --model gemini-1.5-flash-latest

# ä½¿ç”¨é¢„è®¾æç¤ºæ¨¡æ¿
python gemini-stt.py --input meeting.wav --output meeting.srt \
  --api-key YOUR_API_KEY --prompt-preset meeting
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### STT.py - æœ¬åœ°å¤„ç†å¼•æ“

#### åŸºæœ¬å‚æ•°

| å‚æ•° | ç®€å†™ | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|------|--------|
| `--audio` | `-a` | éŸ³é¢‘æ–‡ä»¶è·¯å¾„ | å¿…å¡« |
| `--model` | `-m` | Whisperæ¨¡å‹è·¯å¾„ | å¿…å¡« |
| `--output` | `-o` | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | transcription.txt |
| `--format` | `-f` | è¾“å‡ºæ ¼å¼ (txt/srt/json) | txt |
| `--language` | `-l` | è¯­è¨€ä»£ç  | zh |
| `--device` | `-d` | è®¡ç®—è®¾å¤‡ (cuda/cpu/auto) | auto |
| `--task` | `-t` | ä»»åŠ¡ç±»å‹ (transcribe/translate) | transcribe |

#### é«˜çº§å‚æ•°

```bash
# è°ƒæ•´æ€§èƒ½å‚æ•°
python stt.py -a audio.wav -m model_path -o output.txt \
  --beam-size 5 \
  --compute-type float16 \
  --silence 1000 \
  --no-vad

# è¯´è¯äººåˆ†å‰²å‚æ•°
python stt.py -a audio.wav -m model_path -o output.txt \
  --speakers \
  --speaker-model pyannote_model_path \
  --min-speakers 2 \
  --max-speakers 5 \
  --audio-format auto

# æ‰¹å¤„ç†å‚æ•°
python stt.py --batch \
  -a ./audio_folder/ \
  --output-dir ./results/ \
  --in-memory \
  --keep-temp-files
```

#### è¾“å‡ºæ ¼å¼ç¤ºä¾‹

**TXT æ ¼å¼**:
```
# è½¬å½•æ–‡ä»¶: audio.wav
# è½¬å½•æ—¶é—´: 2024-01-15 10:30:00
# æ£€æµ‹è¯­è¨€: zh, ç½®ä¿¡åº¦: 0.9999

[0.00s -> 3.50s] å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä»Šå¤©çš„ä¼šè®®ã€‚
[3.50s -> 7.20s] ä»Šå¤©æˆ‘ä»¬ä¸»è¦è®¨è®ºé¡¹ç›®è¿›å±•æƒ…å†µã€‚
```

**SRT æ ¼å¼**:
```
1
00:00:00,000 --> 00:00:03,500
å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä»Šå¤©çš„ä¼šè®®ã€‚

2
00:00:03,500 --> 00:00:07,200
ä»Šå¤©æˆ‘ä»¬ä¸»è¦è®¨è®ºé¡¹ç›®è¿›å±•æƒ…å†µã€‚
```

**å¸¦è¯´è¯äººçš„ SRT æ ¼å¼**:
```
1
00:00:00,000 --> 00:00:03,500
[SPEAKER_00] å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä»Šå¤©çš„ä¼šè®®ã€‚

2
00:00:03,500 --> 00:00:07,200
[SPEAKER_01] ä»Šå¤©æˆ‘ä»¬ä¸»è¦è®¨è®ºé¡¹ç›®è¿›å±•æƒ…å†µã€‚
```

### Gemini-STT.py - äº‘ç«¯å¤„ç†å¼•æ“

#### åŸºæœ¬ç”¨æ³•

```bash
# åŸºç¡€éŸ³é¢‘è½¬å½•
python gemini-stt.py --input audio.mp3 --output result.srt \
  --api-key YOUR_API_KEY

# è§†é¢‘æ–‡ä»¶è½¬å½•
python gemini-stt.py --input video.mp4 --output subtitles.srt \
  --api-key YOUR_API_KEY --model gemini-1.5-pro-latest

# ä½¿ç”¨è¿œç¨‹æ–‡ä»¶
python gemini-stt.py --file-id your_uploaded_file_id --output result.srt \
  --api-key YOUR_API_KEY
```

#### ç³»ç»Ÿæç¤ºæ¨¡æ¿

| æ¨¡æ¿åç§° | ç”¨é€” | ç‰¹ç‚¹ |
|----------|------|------|
| `standard` | é€šç”¨è½¬å½• | ä¿æŒåŸå§‹è¯­è¨€ï¼Œå‡†ç¡®è½¬å½• |
| `meeting` | ä¼šè®®è®°å½• | è¯†åˆ«å‘è¨€äººï¼Œè¿‡æ»¤å¡«å……è¯ |
| `interview` | è®¿è°ˆå†…å®¹ | åŒºåˆ†é‡‡è®¿è€…å’Œå—è®¿è€…ï¼Œä¿ç•™æƒ…ç»ª |
| `lecture` | å­¦æœ¯æ¼”è®² | å‡†ç¡®æ•æ‰æœ¯è¯­ï¼Œä¿ç•™å­¦æœ¯è¡¨è¾¾ |
| `condensed` | ç²¾ç®€ç‰ˆæœ¬ | åˆ é™¤å£å¤´ç¦…ï¼Œç®€æ´è¡¨è¾¾ |

```bash
# ä½¿ç”¨ä¼šè®®æ¨¡æ¿
python gemini-stt.py --input meeting.wav --output meeting.srt \
  --api-key YOUR_API_KEY --prompt-preset meeting

# ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤º
python gemini-stt.py --input lecture.mp3 --output lecture.srt \
  --api-key YOUR_API_KEY --use-system-prompt --system-prompt-file custom_prompt.txt
```

#### é«˜çº§å‚æ•°

```bash
# è°ƒæ•´ç”Ÿæˆå‚æ•°
python gemini-stt.py --input audio.wav --output result.srt \
  --api-key YOUR_API_KEY \
  --temperature 0.3 \
  --max-output-tokens 8000 \
  --enable-safety

# æ–‡ä»¶ç®¡ç†
python gemini-stt.py --input audio.wav --output result.srt \
  --api-key YOUR_API_KEY \
  --auto-delete \
  --check-first

# ç½‘ç»œè®¾ç½®
python gemini-stt.py --input audio.wav --output result.srt \
  --api-key YOUR_API_KEY \
  --proxy http://proxy.example.com:8080 \
  --retries 5
```

## ğŸ› ï¸ å·¥å…·ä»‹ç»

### convert_whisper.py - Whisper æ¨¡å‹è½¬æ¢å™¨

è‡ªåŠ¨ä¸‹è½½å¹¶è½¬æ¢ Whisper æ¨¡å‹ä¸º faster-whisper æ ¼å¼ï¼Œæå‡æ¨ç†é€Ÿåº¦ã€‚

```bash
# åŸºæœ¬ä½¿ç”¨
python tools/convert_whisper.py --model_id openai/whisper-large-v3

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•å’Œç²¾åº¦
python tools/convert_whisper.py \
  --model_id Belle-2/Belle-whisper-large-v3-zh \
  --output_dir ./models/whisper-zh \
  --compute_type float16 \
  --force

# æ¸…ç†ä¸‹è½½æ–‡ä»¶
python tools/convert_whisper.py \
  --model_id openai/whisper-medium \
  --clean_download \
  --skip_validation
```

**å‚æ•°è¯´æ˜**:
- `--model_id`: Hugging Face æ¨¡å‹ ID
- `--output_dir`: è½¬æ¢åæ¨¡å‹ä¿å­˜è·¯å¾„
- `--compute_type`: è®¡ç®—ç²¾åº¦ (float16/float32/int8)
- `--force`: å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºç›®å½•
- `--clean_download`: è½¬æ¢å®Œæˆååˆ é™¤åŸå§‹ä¸‹è½½æ–‡ä»¶
- `--skip_validation`: è·³è¿‡æ¨¡å‹éªŒè¯æ­¥éª¤

### get_Pyannote_model.py - Pyannote æ¨¡å‹ç®¡ç†å™¨

ä¸€é”®ä¸‹è½½å’Œé…ç½® Pyannote è¯´è¯äººåˆ†å‰²æ¨¡å‹åŠå…¶ä¾èµ–ã€‚

```bash
# åŸºæœ¬ä¸‹è½½
python tools/get_Pyannote_model.py --output ./pyannote-models

# å¼ºåˆ¶é‡æ–°ä¸‹è½½å’Œé‡æ„é…ç½®
python tools/get_Pyannote_model.py --output ./pyannote-models --force --restructure

# ä¸ä½¿ç”¨èº«ä»½éªŒè¯ (ä»…å…¬å¼€æ¨¡å‹)
python tools/get_Pyannote_model.py --output ./pyannote-models --no-auth

# æ£€æŸ¥æ¨¡å‹ç‰ˆæœ¬
python tools/get_Pyannote_model.py --check-versions

# æ£€æŸ¥ pyannote.audio å®‰è£…çŠ¶æ€
python tools/get_Pyannote_model.py --check-pyannote
```

**åŠŸèƒ½ç‰¹ç‚¹**:
- è‡ªåŠ¨ä¸‹è½½ speaker-diarization-3.1 ä¸»æ¨¡å‹
- è‡ªåŠ¨ä¸‹è½½ä¾èµ–æ¨¡å‹ (wespeakerã€segmentation)
- è‡ªåŠ¨é…ç½®æ¨¡å‹è·¯å¾„å…³ç³»
- ç”Ÿæˆå…¼å®¹çš„ config.yaml æ–‡ä»¶
- éªŒè¯æ¨¡å‹å®Œæ•´æ€§

## âš¡ æ€§èƒ½ä¼˜åŒ–

### GPU åŠ é€Ÿè®¾ç½®

```bash
# æ£€æŸ¥ CUDA ç¯å¢ƒ
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# æŒ‡å®š CUDA è·¯å¾„ (å¦‚æœè‡ªåŠ¨æ£€æµ‹å¤±è´¥)
python stt.py -a audio.wav -m model_path -o output.txt \
  --cuda-path /usr/local/cuda-11.8 \
  --device cuda
```

### å†…å­˜ä¼˜åŒ–

```bash
# ä½¿ç”¨å†…å­˜å¤„ç†æ¨¡å¼ (å¤§æ–‡ä»¶)
python stt.py -a large_file.wav -m model_path -o output.txt \
  --in-memory

# è°ƒæ•´æ‰¹å¤„ç†å¤§å°
python stt.py -a audio.wav -m model_path -o output.txt \
  --compute-type int8  # å‡å°‘å†…å­˜ä½¿ç”¨
```

### é€Ÿåº¦ä¼˜åŒ–

```bash
# ç¦ç”¨ VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) åŠ é€Ÿå¤„ç†
python stt.py -a audio.wav -m model_path -o output.txt \
  --no-vad

# å‡å°‘ beam size åŠ é€Ÿæ¨ç†
python stt.py -a audio.wav -m model_path -o output.txt \
  --beam-size 1

# ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
python tools/convert_whisper.py --model_id openai/whisper-base
```

## ğŸ¯ æ¨èæ¨¡å‹

### Whisper æ¨¡å‹é€‰æ‹©

| æ¨¡å‹å¤§å° | æ¨èç”¨é€” | å†…å­˜éœ€æ±‚ | é€Ÿåº¦ | ç²¾åº¦ |
|----------|----------|----------|------|------|
| whisper-base | å¿«é€Ÿæµ‹è¯• | ~1GB | å¾ˆå¿« | ä¸­ç­‰ |
| whisper-medium | å¹³è¡¡æ€§èƒ½ | ~2GB | å¿« | è‰¯å¥½ |
| whisper-large-v3 | é«˜ç²¾åº¦è‹±æ–‡ | ~3GB | ä¸­ç­‰ | å¾ˆé«˜ |
| Belle-whisper-large-v3-zh | ä¸­æ–‡ä¼˜åŒ– | ~3GB | ä¸­ç­‰ | å¾ˆé«˜ |

### è¯´è¯äººåˆ†å‰²æ¨¡å‹

| æ¨¡å‹ç‰ˆæœ¬ | æ¨èç”¨é€” | æ”¯æŒè¯­è¨€ | æœ€å¤§è¯´è¯äºº |
|----------|----------|----------|------------|
| speaker-diarization-3.1 | é€šç”¨åœºæ™¯ | å¤šè¯­è¨€ | æ— é™åˆ¶ |
| speaker-diarization-3.0 | å…¼å®¹æ€§å¥½ | å¤šè¯­è¨€ | æ— é™åˆ¶ |

## â“ å¸¸è§é—®é¢˜

### å®‰è£…é—®é¢˜

**Q: å®‰è£… pyannote.audio æ—¶å‡ºç°é”™è¯¯**
```bash
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç‰¹å®šç‰ˆæœ¬
pip install pyannote.audio==3.1.1 torch torchaudio
```

**Q: CUDA æ£€æµ‹å¤±è´¥**
```bash
# æ£€æŸ¥ CUDA å®‰è£…
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# æ‰‹åŠ¨æŒ‡å®š CUDA è·¯å¾„
python stt.py --cuda-path /usr/local/cuda-11.8 --device cuda
```

### ä½¿ç”¨é—®é¢˜

**Q: éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ**
```bash
# å®‰è£… FFmpeg è§£å†³å¤§éƒ¨åˆ†æ ¼å¼é—®é¢˜
sudo apt install ffmpeg  # Ubuntu
brew install ffmpeg      # macOS

# æ‰‹åŠ¨æŒ‡å®š FFmpeg è·¯å¾„
python stt.py --ffmpeg-path /usr/local/bin --audio input.m4a

# æˆ–æ‰‹åŠ¨è½¬æ¢æ ¼å¼
ffmpeg -i input.m4a -ar 16000 -ac 1 output.wav
```

**Q: è¯´è¯äººåˆ†å‰²æ•ˆæœä¸ä½³**
```bash
# å°è¯•æŒ‡å®šè¯´è¯äººæ•°é‡
python stt.py --speakers --num-speakers 3

# è°ƒæ•´éŸ³é¢‘è´¨é‡
python stt.py --speakers --audio-format wav
```

**Q: å†…å­˜ä¸è¶³**
```bash
# ä½¿ç”¨è¾ƒå°çš„è®¡ç®—ç²¾åº¦
python stt.py --compute-type int8

# åˆ†æ®µå¤„ç†å¤§æ–‡ä»¶
python stt.py --silence 2000  # å¢åŠ é™éŸ³æ£€æµ‹æ—¶é•¿
```

### API é—®é¢˜

**Q: Gemini API è°ƒç”¨å¤±è´¥**
```bash
# æ£€æŸ¥ API Key (ä»…ä¸Šä¼ æµ‹è¯•)
python gemini-stt.py --input test.wav --api-key YOUR_KEY --upload-only

# ä½¿ç”¨ä»£ç†å’Œç¦ç”¨ä»£ç†
python gemini-stt.py --proxy http://proxy:8080 --input audio.wav --output result.srt --api-key YOUR_KEY
python gemini-stt.py --no-proxy --input audio.wav --output result.srt --api-key YOUR_KEY

# æ£€æŸ¥ç°æœ‰æ–‡ä»¶
python gemini-stt.py --file-id your_file_id --api-key YOUR_KEY --output result.srt
```

## ğŸ”§ å¼€å‘è¯´æ˜

### é¡¹ç›®ç»“æ„
```
SKY-STT/
â”œâ”€â”€ stt.py                    # ä¸»å¤„ç†å¼•æ“ (FasterWhisper + Pyannote)
â”œâ”€â”€ gemini-stt.py            # Gemini API å¼•æ“
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ convert_whisper.py   # Whisper æ¨¡å‹è½¬æ¢å™¨
â”‚   â””â”€â”€ get_Pyannote_model.py # Pyannote æ¨¡å‹ç®¡ç†å™¨
â”œâ”€â”€ LICENSE                   # GPL-3.0 è®¸å¯è¯
â””â”€â”€ README.md                # é¡¹ç›®æ–‡æ¡£
```

